{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Sequence-Classification\" data-toc-modified-id=\"Sequence-Classification-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Sequence Classification</a></span><ul class=\"toc-item\"><li><span><a href=\"#Freezing-Model\" data-toc-modified-id=\"Freezing-Model-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Freezing Model</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import training algorithms: we are using \"DistilBert\" flavor for `SequenceClassification` because of speed.\n",
    "`DistilBertTokenizerFast` is also applied to leverage speed for tokenization. `Collator` is applied to create batch of data for training pipeline. The last import is pipeline object that we can use Hugging face but here we want to use to run our own fine-tuned models.\n",
    "\n",
    "The `datasets` library, a companion to Transformers, we're going to be importing `load_metric`, allowing us to create our own custom metrics while evaluating and training our pipelines, and the `Dataset` object, is our general collection holder for all of our data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, DistilBertForSequenceClassification, DistilBertTokenizerFast, \\\n",
    "     DataCollatorWithPadding, pipeline\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import load_metric, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Fake News Data Set**\n",
    "Fake News Data Set is used to fine-tune BERT model. The data can be downloaded from [Kaggle](https://www.kaggle.com/datasets/jillanisofttech/fake-or-real-news). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6903</td>\n",
       "      <td>Tehran, USA</td>\n",
       "      <td>\\nI’m not an immigrant, but my grandparents ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7341</td>\n",
       "      <td>Girl Horrified At What She Watches Boyfriend D...</td>\n",
       "      <td>Share This Baylee Luciani (left), Screenshot o...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95</td>\n",
       "      <td>‘Britain’s Schindler’ Dies at 106</td>\n",
       "      <td>A Czech stockbroker who saved more than 650 Je...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4869</td>\n",
       "      <td>Fact check: Trump and Clinton at the 'commande...</td>\n",
       "      <td>Hillary Clinton and Donald Trump made some ina...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2909</td>\n",
       "      <td>Iran reportedly makes new push for uranium con...</td>\n",
       "      <td>Iranian negotiators reportedly have made a las...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1357</td>\n",
       "      <td>With all three Clintons in Iowa, a glimpse at ...</td>\n",
       "      <td>CEDAR RAPIDS, Iowa — “I had one of the most wo...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>988</td>\n",
       "      <td>Donald Trump’s Shockingly Weak Delegate Game S...</td>\n",
       "      <td>Donald Trump’s organizational problems have go...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7041</td>\n",
       "      <td>Strong Solar Storm, Tech Risks Today | S0 News...</td>\n",
       "      <td>Click Here To Learn More About Alexandra's Per...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7623</td>\n",
       "      <td>10 Ways America Is Preparing for World War 3</td>\n",
       "      <td>October 31, 2016 at 4:52 am \\nPretty factual e...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1571</td>\n",
       "      <td>Trump takes on Cruz, but lightly</td>\n",
       "      <td>Killing Obama administration rules, dismantlin...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                              title  \\\n",
       "0         8476                       You Can Smell Hillary’s Fear   \n",
       "1        10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2         3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3        10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4          875   The Battle of New York: Why This Primary Matters   \n",
       "5         6903                                        Tehran, USA   \n",
       "6         7341  Girl Horrified At What She Watches Boyfriend D...   \n",
       "7           95                  ‘Britain’s Schindler’ Dies at 106   \n",
       "8         4869  Fact check: Trump and Clinton at the 'commande...   \n",
       "9         2909  Iran reportedly makes new push for uranium con...   \n",
       "10        1357  With all three Clintons in Iowa, a glimpse at ...   \n",
       "11         988  Donald Trump’s Shockingly Weak Delegate Game S...   \n",
       "12        7041  Strong Solar Storm, Tech Risks Today | S0 News...   \n",
       "13        7623       10 Ways America Is Preparing for World War 3   \n",
       "14        1571                   Trump takes on Cruz, but lightly   \n",
       "\n",
       "                                                 text label  \n",
       "0   Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1   Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2   U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3   — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4   It's primary day in New York and front-runners...  REAL  \n",
       "5     \\nI’m not an immigrant, but my grandparents ...  FAKE  \n",
       "6   Share This Baylee Luciani (left), Screenshot o...  FAKE  \n",
       "7   A Czech stockbroker who saved more than 650 Je...  REAL  \n",
       "8   Hillary Clinton and Donald Trump made some ina...  REAL  \n",
       "9   Iranian negotiators reportedly have made a las...  REAL  \n",
       "10  CEDAR RAPIDS, Iowa — “I had one of the most wo...  REAL  \n",
       "11  Donald Trump’s organizational problems have go...  REAL  \n",
       "12  Click Here To Learn More About Alexandra's Per...  FAKE  \n",
       "13  October 31, 2016 at 4:52 am \\nPretty factual e...  FAKE  \n",
       "14  Killing Obama administration rules, dismantlin...  REAL  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_news = pd.read_csv('./Data/fake_or_real_news.csv')\n",
    "\n",
    "data_news[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code segment parses the data_news dataset into a more manageable format\n",
    "\n",
    "titles = []\n",
    "tokenized_titles = []\n",
    "sequence_labels = data_news['label']\n",
    "\n",
    "title, tokenized_title =  [], []\n",
    "for news in data_news['title']:\n",
    "    title.append(news)\n",
    "    tokenized_title.append(news.split(' '))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('You Can Smell Hillary’s Fear',\n",
       " ['You', 'Can', 'Smell', 'Hillary’s', 'Fear'],\n",
       " 'FAKE')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python list for each news\n",
    "title[0], tokenized_title[0], sequence_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['REAL', 'FAKE']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_sequence_labels = list(set(sequence_labels))\n",
    "unique_sequence_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two categories to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 unique sequence labels\n"
     ]
    }
   ],
   "source": [
    "sequence_labels = [unique_sequence_labels.index(l) for l in sequence_labels]\n",
    "\n",
    "print(f'There are {len(unique_sequence_labels)} unique sequence labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final python list is going to be something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You', 'Can', 'Smell', 'Hillary’s', 'Fear']\n",
      "You Can Smell Hillary’s Fear\n",
      "1\n",
      "FAKE\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_title[0])\n",
    "print(title[0])\n",
    "print(sequence_labels[0])\n",
    "print(unique_sequence_labels[sequence_labels[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting all data, we put it in dataset object. Then we can have train-test split by `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['titles', 'label', 'tokens'],\n",
       "        num_rows: 5068\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['titles', 'label', 'tokens'],\n",
       "        num_rows: 1267\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset = Dataset.from_dict(\n",
    "    dict(\n",
    "        titles=title, \n",
    "        label=sequence_labels,\n",
    "        tokens=tokenized_title,\n",
    "    )\n",
    ")\n",
    "news_dataset = news_dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "news_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is first element of our training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'titles': 'Will the GOP Mount a Third-Party Challenge to Trump?',\n",
       " 'label': 0,\n",
       " 'tokens': ['Will',\n",
       "  'the',\n",
       "  'GOP',\n",
       "  'Mount',\n",
       "  'a',\n",
       "  'Third-Party',\n",
       "  'Challenge',\n",
       "  'to',\n",
       "  'Trump?']}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is to instantiate tokenizer with `DistilBertTokenizerFast` from 'distilbert-base-uncased'. FYI, **uncased** means lower or upper case of the words do not matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pre-process function to take in a batch of titles and tokenize them with `DistilBertTokenizerFast`. The question is why we are tokenizing the title if we already have the tokens. The answer is we do not necessarily know the tokens that has been given to us will match up with tokenized version for BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"titles\"], truncation=True) # truncation=True makes sure to exludes instances with more \n",
    "                                                            # 512 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map the tokenizer function for the entire data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5068 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1267 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# go over all our data set, tokenize them\n",
    "seq_clf_tokenized_news = news_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['titles', 'label', 'tokens'],\n",
       "        num_rows: 5068\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['titles', 'label', 'tokens'],\n",
       "        num_rows: 1267\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the first item, we also have `input_ids` and `attention_mask`. These are the items we are going to need in our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'titles': 'Will the GOP Mount a Third-Party Challenge to Trump?',\n",
       " 'label': 0,\n",
       " 'tokens': ['Will',\n",
       "  'the',\n",
       "  'GOP',\n",
       "  'Mount',\n",
       "  'a',\n",
       "  'Third-Party',\n",
       "  'Challenge',\n",
       "  'to',\n",
       "  'Trump?'],\n",
       " 'input_ids': [101,\n",
       "  2097,\n",
       "  1996,\n",
       "  2175,\n",
       "  2361,\n",
       "  4057,\n",
       "  1037,\n",
       "  2353,\n",
       "  1011,\n",
       "  2283,\n",
       "  4119,\n",
       "  2000,\n",
       "  8398,\n",
       "  1029,\n",
       "  102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_clf_tokenized_news['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataCollatorWithPadding` creates batch of data. It also dynamically pads text to the length of the longest element in the batch (on the right), making them all the same length. It's possible to pad your text in the tokenizer function with `padding=True`, dynamic padding is more efficient. This will make the training process faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Collator will pad data so that all examples are the same input length. Attention mask is how we ignore attention scores for padding tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now time to create our actual model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "sequence_clf_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', \n",
    "                                                                         num_labels=len(unique_sequence_labels),)\n",
    "\n",
    "# set an index -> label dictionary\n",
    "sequence_clf_model.config.id2label = {i: l for i, l in enumerate(unique_sequence_labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every model comes with a `config`. In this `config`, there is `id2label` attribute which is a dictionary that has integer as keys and string as values. See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_clf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertConfig {\n",
       "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
       "  \"activation\": \"gelu\",\n",
       "  \"architectures\": [\n",
       "    \"DistilBertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"dim\": 768,\n",
       "  \"dropout\": 0.1,\n",
       "  \"hidden_dim\": 3072,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"REAL\",\n",
       "    \"1\": \"FAKE\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"distilbert\",\n",
       "  \"n_heads\": 12,\n",
       "  \"n_layers\": 6,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"qa_dropout\": 0.1,\n",
       "  \"seq_classif_dropout\": 0.2,\n",
       "  \"sinusoidal_pos_embds\": false,\n",
       "  \"tie_weights_\": true,\n",
       "  \"transformers_version\": \"4.26.1\",\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_clf_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'REAL'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_clf_model.config.id2label[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is the time to have a costume metric. HuggingFace always uses loss as performance metric but we need to calculate accuracy as a simpler metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):  # common method to take in logits and calculate accuracy of the eval set\n",
    "    logits, labels = eval_pred   # logit and label are returning from training loop\n",
    "    predictions = np.argmax(logits, axis=-1) \n",
    "    return metric.compute(predictions=predictions, references=labels) # compute the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take pre-trained knowledge of BERT and transfer that knowledge to our supervised data set by not training too many epochs. The code block below is going to repeat itself again and again because it define our training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "\n",
    "# Training argument\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./news_clf/results\", # Local directory to save check point of our model as fitting\n",
    "    num_train_epochs=epochs,         # minimum of two epochs\n",
    "    per_device_train_batch_size=32,  # batch size for training and evaluation, it common to take around 32, \n",
    "    per_device_eval_batch_size=32,   # sometimes less or more, The smaller batch size, the more change model update \n",
    "    load_best_model_at_end=True,     # Even if we overfit the model by accident, load the best model through checkpoint\n",
    "    \n",
    "    # some deep learning parameters that the trainer is able to take in\n",
    "    warmup_steps = len(seq_clf_tokenized_news['train']) // 5,  # learning rate scheduler by number of warmup steps\n",
    "    weight_decay = 0.05,    # weight decay for our learning rate schedule (regularization)\n",
    "    \n",
    "    logging_steps = 1,  # Tell the model minimum number of steps to log between (1 means logging as much as possible)\n",
    "    log_level = 'info',\n",
    "    evaluation_strategy = 'epoch', # It is \"steps\" or \"epoch\", we choose epoch: how many times to stop training to test\n",
    "    eval_steps = 50,\n",
    "    save_strategy = 'epoch'  # save a check point of our model after each epoch\n",
    ")\n",
    "\n",
    "# Define the trainer:\n",
    "trainer = Trainer(\n",
    "    model=sequence_clf_model,   # take our model (sequence_clf_model)\n",
    "    args=training_args,         # we just set it above\n",
    "    train_dataset=seq_clf_tokenized_news['train'], # training part of dataset\n",
    "    eval_dataset=seq_clf_tokenized_news['test'],   # test (evaluation) part of dataset\n",
    "    compute_metrics=compute_metrics,    # This part is optional but we want to calculate accuracy of our model \n",
    "    data_collator=data_collator         # data colladior with padding. Infact, we may or may not need a data collator\n",
    "                                        # we can check the model to see how it lookes like with or without the collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start training, we can run the trainer **without fine-tune model** to measure performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tokens, titles. If tokens, titles are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1267\n",
      "  Batch size = 32\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 14:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6958811283111572,\n",
       " 'eval_accuracy': 0.4593528018942384,\n",
       " 'eval_runtime': 42.9697,\n",
       " 'eval_samples_per_second': 29.486,\n",
       " 'eval_steps_per_second': 0.931}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get initial metrics: evaluation on test set\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hope the initial loss and accuracy will improve after training. Since we have not fine-tuned the model yet, the metric is random guessing. The feed-forward layer on top of the model has not been updated yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tokens, titles. If tokens, titles are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 5068\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 318\n",
      "  Number of trainable parameters = 66955010\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 20:09, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.528200</td>\n",
       "      <td>0.534550</td>\n",
       "      <td>0.748224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.385628</td>\n",
       "      <td>0.827151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tokens, titles. If tokens, titles are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1267\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./news_clf/results\\checkpoint-159\n",
      "Configuration saved in ./news_clf/results\\checkpoint-159\\config.json\n",
      "Model weights saved in ./news_clf/results\\checkpoint-159\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tokens, titles. If tokens, titles are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1267\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./news_clf/results\\checkpoint-318\n",
      "Configuration saved in ./news_clf/results\\checkpoint-318\\config.json\n",
      "Model weights saved in ./news_clf/results\\checkpoint-318\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./news_clf/results\\checkpoint-318 (score: 0.385628342628479).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=318, training_loss=0.5511337874351807, metrics={'train_runtime': 1213.1417, 'train_samples_per_second': 8.355, 'train_steps_per_second': 0.262, 'total_flos': 80688169304784.0, 'train_loss': 0.5511337874351807, 'epoch': 2.0})"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation loss decreases dramatically after first epoch and accuracy jumped hugely from 0.45 to 0.74."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tokens, titles. If tokens, titles are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1267\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.385628342628479,\n",
       " 'eval_accuracy': 0.8271507498026835,\n",
       " 'eval_runtime': 42.1237,\n",
       " 'eval_samples_per_second': 30.078,\n",
       " 'eval_steps_per_second': 0.95,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'FAKE', 'score': 0.8936770558357239}]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a pipline by passing in our fine-tuned model with tokenizer\n",
    "pipe = pipeline(\"text-classification\", model=sequence_clf_model, tokenizer=tokenizer)\n",
    "pipe('Please add Here We Go by Dispatch to my road trip playlist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./news_clf/results\n",
      "Configuration saved in ./news_clf/results\\config.json\n",
      "Model weights saved in ./news_clf/results\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "# We can save our model on drirectory we specified\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily call our pipline directly from directory. This very useful for deploying our model on the cloud with one line of the code. We can use it with exact same way to get the exact result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./news_clf/results\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"./news_clf/results\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"REAL\",\n",
      "    \"1\": \"FAKE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": null,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file ./news_clf/results\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"./news_clf/results\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"REAL\",\n",
      "    \"1\": \"FAKE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": null,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ./news_clf/results\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at ./news_clf/results.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-classification\", \"./news_clf/results\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'REAL', 'score': 0.9087793827056885}]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'The Battle of New York: Why This Primary Matters'\n",
    "pipe(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'FAKE', 'score': 0.9160932302474976}]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Breaking News: Researchers have discovered a new species of dinosaur that \n",
    "        can breathe fire. The creature, named Pyrodino, is believed to have lived \n",
    "        during the Jurassic period and could shoot flames out of its nostrils, \n",
    "        making it one of the deadliest predators of its time.\"\"\"\n",
    "pipe(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to now we updated all parameters, that is why it takes too much time. Below we freeze all our BERT model except for the classification layer. This is our third option that we freeze all our pre-trained model and only train a layer on top of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\mrezv/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\4dc145c5bd4fdb672dcded7fdc1efd6c2bc55992\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\mrezv/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\4dc145c5bd4fdb672dcded7fdc1efd6c2bc55992\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a new distilbert model\n",
    "frozen_sequence_clf_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-cased', \n",
    "                                                                        num_labels=len(unique_sequence_labels),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to freeze every parameter in the model. the easiest way to freeze is to iterate over all `distilbert.parameters()` and make them as False. It only updates pre_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in frozen_sequence_clf_model.distilbert.parameters():\n",
    "    param.requires_grad = False   # \"False\" makes the parameters unable to update. \"grad\" stands for gradient\n",
    "                                  # it never upgrade during training        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the code above, the only layer allowed to be updated is below:\n",
    "\n",
    "`(pre_classifier): Linear(in_features=768, out_features=768, bias=True)`\n",
    "\n",
    "`(classifier): Linear(in_features=768, out_features=2, bias=True)`\n",
    "\n",
    "`(dropout): Dropout(p=0.2, inplace=False)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leads to much faster training but will yield worse result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frozen_sequence_clf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions[:, 1]\n",
    "\n",
    "    # Calculate the AUC score\n",
    "    auc_score = roc_auc_score(labels, preds)\n",
    "\n",
    "    # Calculate the true positive, false positive, false negative, and true negative values\n",
    "    tp = ((preds >= 0.5) & (labels == 1)).sum()\n",
    "    fp = ((preds >= 0.5) & (labels == 0)).sum()\n",
    "    fn = ((preds < 0.5) & (labels == 1)).sum()\n",
    "    tn = ((preds < 0.5) & (labels == 0)).sum()\n",
    "\n",
    "    # Calculate the precision, recall, and F1 score\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'auc_score': auc_score,\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'fn': fn,\n",
    "        'tn': tn,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "# Training argument\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./news_clf/results\",\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    load_best_model_at_end=True,\n",
    "    \n",
    "    # some deep learning parameters that the Trainer is able to take in\n",
    "    warmup_steps = len(seq_clf_tokenized_news['train']) // 5,  # number of warmup steps for learning rate scheduler,\n",
    "    weight_decay = 0.05,\n",
    "    \n",
    "    logging_steps = 1, \n",
    "    log_level = 'info',\n",
    "    evaluation_strategy = 'epoch',\n",
    "    eval_steps = 50,\n",
    "    save_strategy = 'epoch'\n",
    ")\n",
    "\n",
    "# Define the trainer:\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=sequence_clf_model,\n",
    "    args=training_args,\n",
    "    train_dataset=seq_clf_tokenized_news['train'],\n",
    "    eval_dataset=seq_clf_tokenized_news['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator  # data colladior with padding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tokens, titles. If tokens, titles are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1267\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 10:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.385628342628479,\n",
       " 'eval_precision': 0.7671232876712328,\n",
       " 'eval_recall': 0.9195402298850575,\n",
       " 'eval_f1_score': 0.8364451082897684,\n",
       " 'eval_tp': 560,\n",
       " 'eval_fp': 170,\n",
       " 'eval_fn': 49,\n",
       " 'eval_tn': 488,\n",
       " 'eval_runtime': 41.9918,\n",
       " 'eval_samples_per_second': 30.173,\n",
       " 'eval_steps_per_second': 0.953}"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tokens, titles. If tokens, titles are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 5068\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 318\n",
      "  Number of trainable parameters = 66955010\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 19:48, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Tp</th>\n",
       "      <th>Fp</th>\n",
       "      <th>Fn</th>\n",
       "      <th>Tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.241200</td>\n",
       "      <td>0.367865</td>\n",
       "      <td>0.860670</td>\n",
       "      <td>0.801314</td>\n",
       "      <td>0.829932</td>\n",
       "      <td>488</td>\n",
       "      <td>79</td>\n",
       "      <td>121</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.267700</td>\n",
       "      <td>0.393928</td>\n",
       "      <td>0.818862</td>\n",
       "      <td>0.898194</td>\n",
       "      <td>0.856695</td>\n",
       "      <td>547</td>\n",
       "      <td>121</td>\n",
       "      <td>62</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tokens, titles. If tokens, titles are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1267\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./news_clf/results\\checkpoint-159\n",
      "Configuration saved in ./news_clf/results\\checkpoint-159\\config.json\n",
      "Model weights saved in ./news_clf/results\\checkpoint-159\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tokens, titles. If tokens, titles are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1267\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./news_clf/results\\checkpoint-318\n",
      "Configuration saved in ./news_clf/results\\checkpoint-318\\config.json\n",
      "Model weights saved in ./news_clf/results\\checkpoint-318\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./news_clf/results\\checkpoint-159 (score: 0.3678646683692932).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=318, training_loss=0.24578225891451416, metrics={'train_runtime': 1191.2413, 'train_samples_per_second': 8.509, 'train_steps_per_second': 0.267, 'total_flos': 80688169304784.0, 'train_loss': 0.24578225891451416, 'epoch': 2.0})"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()  # ~23min -> ~6min on my laptop with all of distilbert frozen with a worse loss/accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tokens, titles. If tokens, titles are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1267\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 47:01:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3678646683692932,\n",
       " 'eval_precision': 0.8606701940035273,\n",
       " 'eval_recall': 0.8013136288998358,\n",
       " 'eval_f1_score': 0.8299319727891158,\n",
       " 'eval_tp': 488,\n",
       " 'eval_fp': 79,\n",
       " 'eval_fn': 121,\n",
       " 'eval_tn': 579,\n",
       " 'eval_runtime': 41.6822,\n",
       " 'eval_samples_per_second': 30.397,\n",
       " 'eval_steps_per_second': 0.96,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"mark\">This is a general rule: when we update the entire model we will get slower run but higher performance. If we freeze the entire BERT model, it gives much faster training time but probably will get worse result. There is middle ground that we freeze part of model to see how it will work for us.</span>"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "605.8px",
    "left": "1380px",
    "top": "46.8px",
    "width": "344.268px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
